{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GvYheQmapMq"
      },
      "source": [
        "# Python演習課題1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv7tagc1atTc"
      },
      "source": [
        "## 課題1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4oSY5udavEu"
      },
      "source": [
        "### 問1\n",
        "\n",
        "文字列\"datascience\"の文字を逆に（末尾から先頭に向かって）並べた文字列を出力してください"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b34Yn70dal4y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "反転後の文字列: ecneicsatad\n"
          ]
        }
      ],
      "source": [
        "input = \"datascience\"\n",
        "reversed = input[::-1]\n",
        "print(f\"反転後の文字列: {reversed}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVuEIAKza443"
      },
      "source": [
        "### 問2\n",
        "\n",
        "「ヘエルスシトンニキア」という文字列の1,3,5,7,9文字目を取り出して連結した文字列を出力してください\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vMZAn2xLa-DI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "抽出・連結された文字列: ヘルシンキ\n"
          ]
        }
      ],
      "source": [
        "input_string = \"ヘエルスシトンニキア\"\n",
        "extracted_string = input_string[::2]\n",
        "\n",
        "print(f\"抽出・連結された文字列: {extracted_string}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PqQRc3Ya-im"
      },
      "source": [
        "### 問3\n",
        "\n",
        "「ヘルシンキ」＋「エストニア」の文字を先頭から交互に連結して文字列「ヘエルスシトンニキア」を出力してください\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "96eYhROCbA20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "交互に連結された文字列: ヘエルスシトンニキア\n"
          ]
        }
      ],
      "source": [
        "string1 = \"ヘルシンキ\"\n",
        "string2 = \"エストニア\"\n",
        "interwoven_chars = [char for pair in zip(string1, string2) for char in pair]\n",
        "\n",
        "# 結果の文字列を生成\n",
        "result_string = \"\".join(interwoven_chars)\n",
        "\n",
        "# 結果を出力\n",
        "print(f\"交互に連結された文字列: {result_string}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4-ExPPSbDEL"
      },
      "source": [
        "### 問4\n",
        "\n",
        "\"Character education based on the fundamental spirit of Buddhism and the Shiguzeigan\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成してください\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oUTnc-HwbEqP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "分解された単語のリスト: ['Character', 'education', 'based', 'on', 'the', 'fundamental', 'spirit', 'of', 'Buddhism', 'and', 'the', 'Shiguzeigan']\n",
            "各単語の文字数のリスト: [9, 9, 5, 2, 3, 11, 6, 2, 8, 3, 3, 11]\n"
          ]
        }
      ],
      "source": [
        "# 入力英文\n",
        "input_sentence = \"Character education based on the fundamental spirit of Buddhism and the Shiguzeigan\"\n",
        "\n",
        "words = input_sentence.split()\n",
        "\n",
        "#    新しいリストとして抽出する。\n",
        "word_lengths = [len(word) for word in words]\n",
        "\n",
        "# 結果を出力\n",
        "print(f\"分解された単語のリスト: {words}\")\n",
        "print(f\"各単語の文字数のリスト: {word_lengths}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfk9Ky3LbOye"
      },
      "source": [
        "### 問5\n",
        "\n",
        "\"It is not the strongest of the species that survives, nor the most intelligent that survives. It is the one that is most adaptable to change.\"という文を単語に分解し，1, 2, 5, 6, 8, 9, 16番目の単語の先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）を格納した辞書を作成してください"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yRinYBhWbWah"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "入力英文: It is not the strongest of the species that survives, nor the most intelligent that survives. It is the one that is most adaptable to change.\n",
            "分解後の単語リスト: ['it', 'is', 'not', 'the', 'strongest', 'of', 'the', 'species', 'that', 'survives', 'nor', 'the', 'most', 'intelligent', 'that', 'survives', 'it', 'is', 'the', 'one', 'that', 'is', 'most', 'adaptable', 'to', 'change']\n",
            "対象の単語の位置 (1から): [1, 2, 5, 6, 8, 9, 16]\n",
            "作成された辞書: {'it': 1, 'is': 2, 'st': 5, 'of': 6, 'sp': 8, 'th': 9, 'su': 16}\n"
          ]
        }
      ],
      "source": [
        "input_sentence = \"It is not the strongest of the species that survives, nor the most intelligent that survives. It is the one that is most adaptable to change.\"\n",
        "\n",
        "import string\n",
        "# 句読点の除去\n",
        "cleaned_sentence = input_sentence.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "\n",
        "# string.split() を使って、英文をスペースで区切り、単語のリストに分解する。\n",
        "words = cleaned_sentence.split()\n",
        "\n",
        "# 辞書を作成するための対象単語の位置リスト (1-based index)\n",
        "target_indices_1based = [1, 2, 5, 6, 8, 9, 16]\n",
        "\n",
        "# 辞書を格納する変数を初期化\n",
        "result_dictionary = {}\n",
        "\n",
        "# リストを走査し、指定された位置の単語を処理する\n",
        "for index_1based in target_indices_1based:\n",
        "    # リストのインデックスは 0 から始まるため、1 を引く\n",
        "    index_0based = index_1based - 1\n",
        "\n",
        "    # 単語のリストの範囲内かチェック\n",
        "    if index_0based < len(words):\n",
        "        word = words[index_0based]\n",
        "\n",
        "        # 単語の先頭2文字を取り出す\n",
        "        prefix_2chars = word[:2]\n",
        "\n",
        "        # 辞書に格納: キー=先頭2文字, 値=単語の位置 (1-based index)\n",
        "        # 辞書のキーが重複する場合、後から処理された値で上書きされる\n",
        "        result_dictionary[prefix_2chars] = index_1based\n",
        "    else:\n",
        "        print(f\"Warning: Index {index_1based} is out of bounds for the word list.\")\n",
        "\n",
        "\n",
        "# 結果を出力\n",
        "print(f\"入力英文: {input_sentence}\")\n",
        "print(f\"分解後の単語リスト: {words}\")\n",
        "print(f\"対象の単語の位置 (1から): {target_indices_1based}\")\n",
        "print(f\"作成された辞書: {result_dictionary}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
